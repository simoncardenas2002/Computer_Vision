{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPFUH+w+xjeJpIHaXgiP1T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simoncardenas2002/Computer_Vision/blob/master/json_tfrecord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_WqU0hspdXL",
        "outputId": "984493c5-137c-4dc1-b004-2e1bf182a558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Para comenzar se convertirá el archivo que nos da LinkedAI en json a un formato csv para poder trabajarlo posteriormente"
      ],
      "metadata": {
        "id": "nGzZyZT78H1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "\n",
        "!pip install tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btccc2fN1WEL",
        "outputId": "38c9f63b-2b43-4827-b50b-2ac50b9b9353"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ElKoCyhk6YIA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_zip= \"/content/drive/MyDrive/computer_vision/data_crop_detection.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip,\"r\")\n",
        "zip_ref.extractall(\"dataset_original\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "8itON9nN2UYi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Primero el archivo de train"
      ],
      "metadata": {
        "id": "b4hf8w4X8YXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type_file= \"train\"\n",
        "path=\"/content/drive/MyDrive/computer_vision/train.json\"\n",
        "data_file= open(path)\n",
        "data= json.load(data_file)"
      ],
      "metadata": {
        "id": "LF0RCAad2yHt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_list=[]\n",
        "\n",
        "for classification in data:\n",
        "  width,height =classification[\"width\"],classification[\"height\"]\n",
        "  image=classification[\"image\"]\n",
        "  for item in classification[\"tags\"]:\n",
        "    name= item[\"name\"]\n",
        "    xmin= item[\"pos\"][\"x\"]\n",
        "    ymin= item[\"pos\"][\"y\"]\n",
        "    xmax= item[\"pos\"][\"x\"]+item[\"pos\"][\"w\"]\n",
        "    ymax= item[\"pos\"][\"y\"]+item[\"pos\"][\"h\"]\n",
        "\n",
        "    value= (image,width,height,name,xmin,ymin,xmax,ymax)\n",
        "    csv_list.append(value)\n",
        "\n",
        "column_name=[\"filename\",\"width\",\"height\",\"class\",\"xmin\",\"ymin\",\"xmax\",\"ymax\"]\n",
        "\n",
        "csv_df = pd.DataFrame(csv_list, columns=column_name)\n",
        "\n",
        "csv_df.to_csv(\"/content/{}_labels.csv\".format(type_file))\n"
      ],
      "metadata": {
        "id": "1FXVRpFO3eIY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ahora el archivo de test"
      ],
      "metadata": {
        "id": "oUuj2oQK8cvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type_file= \"test\"\n",
        "path=\"/content/drive/MyDrive/computer_vision/test.json\"\n",
        "data_file= open(path)\n",
        "data= json.load(data_file)"
      ],
      "metadata": {
        "id": "cDsjtqUk8fks"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_list=[]\n",
        "\n",
        "for classification in data:\n",
        "  width,height =classification[\"width\"],classification[\"height\"]\n",
        "  image=classification[\"image\"]\n",
        "  for item in classification[\"tags\"]:\n",
        "    name= item[\"name\"]\n",
        "    xmin= item[\"pos\"][\"x\"]\n",
        "    ymin= item[\"pos\"][\"y\"]\n",
        "    xmax= item[\"pos\"][\"x\"]+item[\"pos\"][\"w\"]\n",
        "    ymax= item[\"pos\"][\"y\"]+item[\"pos\"][\"h\"]\n",
        "\n",
        "    value= (image,width,height,name,xmin,ymin,xmax,ymax)\n",
        "    csv_list.append(value)\n",
        "\n",
        "column_name=[\"filename\",\"width\",\"height\",\"class\",\"xmin\",\"ymin\",\"xmax\",\"ymax\"]\n",
        "\n",
        "csv_df = pd.DataFrame(csv_list, columns=column_name)\n",
        "\n",
        "csv_df.to_csv(\"/content/{}_labels.csv\".format(type_file))"
      ],
      "metadata": {
        "id": "byML-Duj8lpY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformaremos a TFRecord"
      ],
      "metadata": {
        "id": "D4L8QWx6YipD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos object detection"
      ],
      "metadata": {
        "id": "sUZwXSA2Ypu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFuYRlpjYcdW",
        "outputId": "92b4afc1-b14f-4420-87e3-6aee2076e879"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/models\n",
            "Note: switching to '58d19c67e1d30d905dd5c6e5092348658fed80af'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 58d19c67e Internal change\n",
            "Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,203 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,668 kB]\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,039 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,334 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,561 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,341 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,150 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,208 kB]\n",
            "Fetched 16.9 MB in 3s (6,536 kB/s)\n",
            "Reading package lists... Done\n",
            "Selecting previously unselected package python2-minimal.\n",
            "(Reading database ... 122519 files and directories currently installed.)\n",
            "Preparing to unpack .../python2-minimal_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package libpython2-stdlib:amd64.\n",
            "Preparing to unpack .../libpython2-stdlib_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up python2-minimal (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package python2.\n",
            "(Reading database ... 122548 files and directories currently installed.)\n",
            "Preparing to unpack .../00-python2_2.7.17-2ubuntu4_amd64.deb ...\n",
            "Unpacking python2 (2.7.17-2ubuntu4) ...\n",
            "Selecting previously unselected package tk8.6-blt2.5.\n",
            "Preparing to unpack .../01-tk8.6-blt2.5_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package blt.\n",
            "Preparing to unpack .../02-blt_2.5.3+dfsg-4_amd64.deb ...\n",
            "Unpacking blt (2.5.3+dfsg-4) ...\n",
            "Selecting previously unselected package libimagequant0:amd64.\n",
            "Preparing to unpack .../03-libimagequant0_2.12.2-1.1_amd64.deb ...\n",
            "Unpacking libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Selecting previously unselected package python-backports.functools-lru-cache.\n",
            "Preparing to unpack .../04-python-backports.functools-lru-cache_1.5-3build1_all.deb ...\n",
            "Unpacking python-backports.functools-lru-cache (1.5-3build1) ...\n",
            "Selecting previously unselected package python-soupsieve.\n",
            "Preparing to unpack .../05-python-soupsieve_1.9.5+dfsg-1_all.deb ...\n",
            "Unpacking python-soupsieve (1.9.5+dfsg-1) ...\n",
            "Selecting previously unselected package python-bs4.\n",
            "Preparing to unpack .../06-python-bs4_4.8.2-1_all.deb ...\n",
            "Unpacking python-bs4 (4.8.2-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../07-python-pkg-resources_44.0.0-2ubuntu0.1_all.deb ...\n",
            "Unpacking python-pkg-resources (44.0.0-2ubuntu0.1) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../08-python-chardet_3.0.4-4build1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-4build1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.14.0-2_all.deb ...\n",
            "Unpacking python-six (1.14.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../10-python-webencodings_0.5.1-1ubuntu1_all.deb ...\n",
            "Unpacking python-webencodings (0.5.1-1ubuntu1) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../11-python-html5lib_1.0.1-2_all.deb ...\n",
            "Unpacking python-html5lib (1.0.1-2) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../12-python-lxml_4.5.0-1ubuntu0.5_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.5.0-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../13-python-olefile_0.46-2_all.deb ...\n",
            "Unpacking python-olefile (0.46-2) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../14-python-pil_6.2.1-3_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (6.2.1-3) ...\n",
            "Selecting previously unselected package python-tk.\n",
            "Preparing to unpack .../15-python-tk_2.7.18-1_amd64.deb ...\n",
            "Unpacking python-tk (2.7.18-1) ...\n",
            "Setting up tk8.6-blt2.5 (2.5.3+dfsg-4) ...\n",
            "Setting up libpython2-stdlib:amd64 (2.7.17-2ubuntu4) ...\n",
            "Setting up blt (2.5.3+dfsg-4) ...\n",
            "Setting up python2 (2.7.17-2ubuntu4) ...\n",
            "Setting up python-six (1.14.0-2) ...\n",
            "Setting up libimagequant0:amd64 (2.12.2-1.1) ...\n",
            "Setting up python-backports.functools-lru-cache (1.5-3build1) ...\n",
            "Setting up python-tk (2.7.18-1) ...\n",
            "Setting up python-webencodings (0.5.1-1ubuntu1) ...\n",
            "Setting up python-olefile (0.46-2) ...\n",
            "Setting up python-lxml:amd64 (4.5.0-1ubuntu0.5) ...\n",
            "Setting up python-html5lib (1.0.1-2) ...\n",
            "Setting up python-pkg-resources (44.0.0-2ubuntu0.1) ...\n",
            "Setting up python-pil:amd64 (6.2.1-3) ...\n",
            "Setting up python-soupsieve (1.9.5+dfsg-1) ...\n",
            "Setting up python-chardet (3.0.4-4build1) ...\n",
            "Setting up python-bs4 (4.8.2-1) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "/content/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n",
            "2023-04-27 20:24:38.331084: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-27 20:24:39.642044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usaremos el código que tensorflow nos da para un detector de objetos lo mas optimizado posible"
      ],
      "metadata": {
        "id": "8V-jmZsucEMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/tensorflow-1.14/training.html"
      ],
      "metadata": {
        "id": "I-28ukascLlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es importante cambiar tanto las clases como las direcciones correspondiendo a nuestro archivo"
      ],
      "metadata": {
        "id": "PoskfPwscVHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Usage:\n",
        "\n",
        "# Create train data:\n",
        "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
        "\n",
        "# Create test data:\n",
        "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append(\"../../models/research\")\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "# for multiple labels add more else if statements\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == \"crop\":  # 'ship': #Esto es lo mas importante de modificar, las clases de nuestro archivo\n",
        "        return 1\n",
        "    \n",
        "    # comment upper if statement and uncomment these statements for multiple labelling\n",
        "    # if row_label == FLAGS.label0:\n",
        "    #   return 1\n",
        "    # elif row_label == FLAGS.label1:\n",
        "    #   return 0\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    # check if the image format is matching with your images.\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "output_path=\"train.record\"\n",
        "image_dir=\"/content/dataset_original/data_crop_detection\"\n",
        "csv_input= \"/content/train_labels.csv\"\n",
        "\n",
        "writer = tf.io.TFRecordWriter(output_path)\n",
        "path = os.path.join(image_dir)\n",
        "examples = pd.read_csv(csv_input)\n",
        "grouped = split(examples, 'filename')\n",
        "for group in grouped:\n",
        "    tf_example = create_tf_example(group, path)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bz0oWQQZ0Nq",
        "outputId": "be505778-5e66-48bb-891f-f8c3a9a6c09d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/models/research/train.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo anterior también se debe hacer con test"
      ],
      "metadata": {
        "id": "zEKNUadLdIg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Usage:\n",
        "\n",
        "# Create train data:\n",
        "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/train_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/train.record\n",
        "\n",
        "# Create test data:\n",
        "python generate_tfrecord.py --label=<LABEL> --csv_input=<PATH_TO_ANNOTATIONS_FOLDER>/test_labels.csv  --output_path=<PATH_TO_ANNOTATIONS_FOLDER>/test.record\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "sys.path.append(\"../../models/research\")\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "\n",
        "# TO-DO replace this with label map\n",
        "# for multiple labels add more else if statements\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == \"crop\":  # 'ship': #Esto es lo mas importante de modificar, las clases de nuestro archivo\n",
        "        return 1\n",
        "    \n",
        "    # comment upper if statement and uncomment these statements for multiple labelling\n",
        "    # if row_label == FLAGS.label0:\n",
        "    #   return 1\n",
        "    # elif row_label == FLAGS.label1:\n",
        "    #   return 0\n",
        "    else:\n",
        "        None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    # check if the image format is matching with your images.\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "output_path=\"test.record\"\n",
        "image_dir=\"/content/dataset_original/data_crop_detection\"\n",
        "csv_input= \"/content/test_labels.csv\"\n",
        "\n",
        "writer = tf.io.TFRecordWriter(output_path)\n",
        "path = os.path.join(image_dir)\n",
        "examples = pd.read_csv(csv_input)\n",
        "grouped = split(examples, 'filename')\n",
        "for group in grouped:\n",
        "    tf_example = create_tf_example(group, path)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "\n",
        "writer.close()\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFoXI3wAc69P",
        "outputId": "8ff473f9-fc38-4b10-d330-14a02ead18d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created the TFRecords: /content/models/research/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Así logramos convertir de csv a formato TFRecord"
      ],
      "metadata": {
        "id": "CwDrSObQdgCy"
      }
    }
  ]
}